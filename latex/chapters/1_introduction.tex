\chapter{Introduction}
\label{sec:introduction}

The interaction of a user with an end device such as a smartphone or a computer is very diverse and difficult to predict.
Nevertheless, user-specific (personalized) as well as global (collaborative) patterns can possibly be worked out with the help of preceding user interactions.
These could be used to predict the intention of a user or a group of users.
It is interesting to know to what level of detail these predictions can be made reliably.
By making use of the continous on-device data an attempt can be made to gain more insights in the user behavior or even forecast their next actions.

It suggests itself to implement this with the help of user interactions in sessions on Android devices.
For this purpose, the Sequential UI Tree data of the device could be tracked, filtered and labeled.
After preprocessing, it could be trained with a machine learning model to find similar interaction sequences and then make predictions.
These can then be very coarse, such as predicting the next app.
Or they can be very detailed, e.g., determining the next user action, such as filling out a form field.

A concept will be developed on how a model for predicting user intent could be built and how it could be applied to the user session.
To this end, possibilities for collecting and vectorizing sequential UI trees (e.g., from the Android Accessibility Service) will be discussed.
The performance of the model can be measured, for example, by indicators such as the amount of training data and time spent on the learning process.

\begin{figure}[htbp!]
    \centering
    \includesvg[width=\textwidth]{graphics/vectorization.svg}
    \caption[Schema of ML-algorithm predicting user intent]{
        Possible procedure using a Machine-Learning algorithm to predict the next intent from a beginning user session:
        The input (1) can be a sequence of Android tree data.
        With help of a Machine-Learning-Model (2) (e.g. RNN) a vector representation can be trained and then predict the most probable action or screen (3) from a given starting sequence, but also can be improvde through the users feedback.
    }
    \label{fig:encode-decode}
\end{figure}

% Zusammenfassen in die wichtigste Aussage: machine learning ist spannend für die Vorhersage weil es Usergruppen erstellt, die sensiblen Daten rausgefiltert werden und ....?
Furthermore, the machine learning model could provide the following benefits in addition to intent prediction:
\begin{itemize}
    \item reduction of the complexity and size of the UI tree
    \item creation of user groups that have similar behavior when using digital UI systems \cite{jayarajah2015need}
    \item elimination of technical expertise on individual features that would be required to manually compare user sessions \cite{ghods2019activity2vec}
    \item consideration of a user's history over time (sequential)
    \item comparison of user interactions without providing privacy invasive information
    \item supporting app developers to improve their app design and usability
    \item application in psychology and market research
    \item pre-loading of processes on devices (energy savings) \cite{shen2019deepapp}
\end{itemize}

As listed above, many fields of application can profit by elaborating such a system.
It would be exciting to know, how the concrete concept would look like and if it can be implemented successfully e.g. to improve the user experience on end-user devices.


\section{The Role of Intent Prediction}
\label{sec:role-intent-prediction}

The term \ti{intent} can have ambiguous meanings and can be used in different context.
In the dictionary it is described as the fact of intending something, so it is planned to do~\cite{dictionaryIntent}.
Generally we can assume that intent is a stronger desire to accomplish ones intension.
Kofler and Hanjalic et al.~\cite{kofler2016user} also describe the intent as \quotes{immediate reason, purpose, or goal [\ldots] that motivates a user to} act.

The aim or purpose must be differentiated from the actual user input, also known as interaction.
So the intent can be seen as the preliminary stage of interaction.
Gestures and click sequences then are the concrete actions, and might fulfill a (small) part of the users intent.
Therefore, in this work it is not the goal to obtain the users full intent, but to work out factors, such as user inputs or gestures, which hint to the intent of the user.
Further, \ti{prediction} describes that the intent or factors of intent should be available (calculated) before they have actually happened or were measured.

\todo{Explain screen, view, flow, click}

But it can be easily replaced by more semantic data, which might even be easier to predict.
Descriptive User intent embedding as preliminary stage, which can be applied with Screen2Words\cite{wang2021screen2words} in a similar fashion.
difference intent / interaction / screen / flow / click


\section{Necessity of Vectors for Android UI}
\label{sec:necessity-of-vectors-for-android-ui}
\todo{Explain how many time a user spents on a mobile device, facilitate steps, make it more productive, qualitative user experience}


Motivation for transforming Android UI tree data to vectors

- open source code for predicting next user click / action
- evaluate and compare existing approaches
- provide tools to reduce screen sequences to vectors
- how to work with multidimensional (multi-modal) data in RNNs

- Low Button depth: number of clicks until one gets to the action \cite{lee2018click}

- Explain intent, and the other words in the title

Contributions: \cite{zhou2021large}
• An analysis of a large-scale dataset of mobile user click se-
quences that reveals rich factors and complexity in modeling
click behaviors, which contributes new knowledge to under-
stand mobile interaction behaviors.
• A Transformer-based deep model that predicts next element
to click based on the user click history and the current screen
and time. The model does not rely on a vocabulary of prede-
fined UI elements and provides a general solution for model-
ing arbitrary UI elements for click prediction.
• A thorough experiment that compares our deep model with
multiple alternative designs and baseline models, and an
analysis of model behaviors and benefits that the model can
bring to improve mobile interaction.

Contributions: \cite{li2021screen2vec}
Screen2Vec: a new self-supervised technique for generating
more comprehensive semantic embeddings of GUI screens
and components using their textual content, visual design
and layout patterns, and app meta-data.
(2) An open-sourced GUI embedding model trained using the
Screen2Vec technique on the Rico [9] dataset that can be
used off-the-shelf.
(3) Several sample downstream tasks that showcase the model’s
usefulness.

In computer science there often coexists multiple (correct) solutions to the same problem.
Many technologies have the capabilities of achieving a similar result, but are specialized in the one or the other way.
That led to the first question

\quotes{What is a suitable model for the prediction of user intent?}.

\quotes{At what level of detail the predictions can be made?}


\label{subsec:motivation}
\todo{P1.1. What is the large scope of the problem?}
\todo{P1.2. What is the specific problem?}

% Second Paragraph
% CORE MESSAGE OF THIS PARAGRAPH:
\todo{P2.1. The second paragraph should be about what have others been doing}
\todo{P2.2. Why is the problem important? Why was this work carried out?}

% Third Paragraph
% CORE MESSAGE OF THIS PARAGRAPH:
\todo{P3.1. What have you done?}
\todo{P3.2. What is new about your work?}

% Fourth paragraph
% CORE MESSAGE OF THIS PARAGRAPH:
\todo{P4.1. What did you find out? What are the concrete results?}
\todo{P4.2. What are the implications? What does this mean for the bigger picture?}

%LaTeX hints are provided in \autoref{chap:latexhints}.
